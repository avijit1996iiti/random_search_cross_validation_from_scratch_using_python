{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_params_search_space():\n",
    "    # Define the hyperparameter search space\n",
    "    param_space = {\n",
    "        'param1': list(range(1, 11)),\n",
    "        'param2': [0.1, 0.5, 1.0],\n",
    "        'param3': ['option1', 'option2', 'option3']\n",
    "    }\n",
    "    return param_space\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Model and Cross-Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(params, train_data, train_labels, val_data, val_labels):\n",
    "    # Instantiate and train your model with given hyperparameters\n",
    "    model = YourModel(param1=params['param1'], param2=params['param2'], param3=params['param3'])\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(train_data, train_labels)\n",
    "    \n",
    "    # Make predictions on the validation data\n",
    "    predictions = model.predict(val_data)\n",
    "    \n",
    "    # Evaluate the model using a metric (e.g., accuracy)\n",
    "    accuracy = accuracy_score(val_labels, predictions)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_cross_validation(data, labels, num_folds=5, num_searches=10):\n",
    "    param_space = random_params_search_space()\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    \n",
    "    best_params = None\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for _ in range(num_searches):\n",
    "        # Randomly sample hyperparameters\n",
    "        params = {key: random.choice(value) for key, value in param_space.items()}\n",
    "        \n",
    "        total_accuracy = 0.0\n",
    "        for train_idx, val_idx in kf.split(data):\n",
    "            train_data, train_labels = data[train_idx], labels[train_idx]\n",
    "            val_data, val_labels = data[val_idx], labels[val_idx]\n",
    "            \n",
    "            accuracy = train_and_evaluate_model(params, train_data, train_labels, val_data, val_labels)\n",
    "            total_accuracy += accuracy\n",
    "        \n",
    "        # Calculate average accuracy across folds\n",
    "        avg_accuracy = total_accuracy / num_folds\n",
    "        \n",
    "        # Update best parameters if current model is better\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_params = params\n",
    "    \n",
    "    return best_params, best_accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Putting It All Together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assuming you have your data and labels loaded\n",
    "data = ...\n",
    "labels = ...\n",
    "\n",
    "best_params, best_accuracy = random_search_cross_validation(data, labels)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Random Search Cross Validation from scratch provides a deeper understanding of the hyperparameter tuning process. While libraries like scikit-learn provide convenient functions for hyperparameter tuning, knowing the underlying mechanisms allows for greater customization and control.\n",
    "\n",
    "Remember, the key to effective hyperparameter tuning is striking a balance between exploration and exploitation. Random Search efficiently explores the hyperparameter space, helping you find optimal configurations for your machine learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
